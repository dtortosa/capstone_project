{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd398747",
   "metadata": {},
   "source": [
    "# Processing EUR Twitter sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128446d2",
   "metadata": {},
   "source": [
    "In this notebook, I am going to load the tweets about the European Central Bank and European Union countries in order to estimate sentiment around the Euro in each day. This will be used as a proxy of the expectations of the economic agents about this fiat currency (see the README for further details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec5c3e",
   "metadata": {},
   "source": [
    "Set the working directory as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c6e884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/dftortosa/Windows/Users/dftor/Documents/diego_docs/industry/data_incubator/capstone_project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/media/dftortosa/Windows/Users/dftor/Documents/diego_docs/industry/data_incubator/capstone_project/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775799a",
   "metadata": {},
   "source": [
    "## Load tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024495ae",
   "metadata": {},
   "source": [
    "List the paths all json files with Twitter data about the Euro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d3a264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = [\"search_euro_bank_twitter_1999_1_1.json\",\n",
    "              \"hashtag_euro_bank_twitter_1999_1_1.json\",\n",
    "              \"search_european_union_economy_twitter_1999_1_1.json\",\n",
    "              \"search_eu_debt_crisis_twitter_1999_1_1.json\", \n",
    "              \"search_greece_economy_twitter_1999_1_1.json\",\n",
    "              \"search_italy_economy_twitter_1999_1_1.json\",\n",
    "              \"search_spain_economy_twitter_1999_1_1.json\",\n",
    "              \"search_portugal_economy_twitter_1999_1_1.json\",\n",
    "              \"search_cyprus_economy_twitter_1999_1_1.json\",\n",
    "              \"search_slovenia_economy_twitter_1999_1_1.json\",\n",
    "              \"search_france_economy_twitter_1999_1_1.json\",\n",
    "              \"search_belgium_economy_twitter_1999_1_1.json\",\n",
    "              \"search_croatia_economy_twitter_1999_1_1.json\", \n",
    "              \"search_ireland_economy_twitter_1999_1_1.json\",\n",
    "              \"search_germany_economy_twitter_1999_1_1.json\", \n",
    "              \"search_netherlands_economy_twitter_1999_1_1.json\", \n",
    "              \"search_finland_economy_twitter_1999_1_1.json\", \n",
    "              \"search_austria_economy_twitter_1999_1_1.json\", \n",
    "              \"search_luxembourg_economy_twitter_1999_1_1.json\", \n",
    "              \"search_slovakia_economy_twitter_1999_1_1.json\", \n",
    "              \"search_malta_economy_twitter_1999_1_1.json\", \n",
    "              \"search_estonia_economy_twitter_1999_1_1.json\", \n",
    "              \"search_latvia_economy_twitter_1999_1_1.json\", \n",
    "              \"search_lithuania_economy_twitter_1999_1_1.json\", \n",
    "              \"search_trichet_twitter.json\", \n",
    "              \"hashtag_draghi_twitter.json\", \n",
    "              \"hashtag_lagarde_twitter.json\"]\n",
    "len(list_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a63d4e",
   "metadata": {},
   "source": [
    "Read all jason files in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b84396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 19.4 s, total: 1min 45s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "\n",
    "def read_tweet_data(path):\n",
    "    return pd.read_json(\"data/json_files/\"+path, lines=True)\n",
    "\n",
    "with mp.Pool(10) as pool:\n",
    "    list_input_df = list(pool.map(read_tweet_data, list_paths))\n",
    "        #for each row in tweets_df_en[\"rawContent\"], apply sentiment_per_row across 10 cores\n",
    "        #https://stackoverflow.com/questions/45545110/make-pandas-dataframe-apply-use-all-cores\n",
    "    pool.close()\n",
    "#list_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c6c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error \n",
    "#alternative approach to load the json files, slower and larger memory footprint, so avoid running it\n",
    "\n",
    "%%time\n",
    "import pandas as pd\n",
    "list_input_df = list(map(lambda path: pd.read_json(\"data/json_files/\"+path, lines=True), list_paths))\n",
    "list_input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b68dc",
   "metadata": {},
   "source": [
    "Combine all data frames within the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900d4197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1562541528740151296</td>\n",
       "      <td>2022-08-24 20:45:05+00:00</td>\n",
       "      <td>Economic Calendar for Tomorrow:\\n\\nðŸ‡©ðŸ‡ª1) German...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1562521759454138368</td>\n",
       "      <td>2022-08-24 19:26:32+00:00</td>\n",
       "      <td>#EURUSD at 0.99 for the first time since 2003....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1562515396330422275</td>\n",
       "      <td>2022-08-24 19:01:15+00:00</td>\n",
       "      <td>The European Central Bank (ECB) is planning to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1562510373445545985</td>\n",
       "      <td>2022-08-24 18:41:17+00:00</td>\n",
       "      <td>In the digital economy, cash is no longer a us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1562499651952996352</td>\n",
       "      <td>2022-08-24 17:58:41+00:00</td>\n",
       "      <td>Reading: What the U.S. Federal Reserve must do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34302</th>\n",
       "      <td>1173870255543902214</td>\n",
       "      <td>2019-09-17 08:04:13+00:00</td>\n",
       "      <td>Pulver endgÃ¼ltig verschossen, #EZB-Rat tief ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34303</th>\n",
       "      <td>1173862961817014273</td>\n",
       "      <td>2019-09-17 07:35:14+00:00</td>\n",
       "      <td>#ECB, i.c. #Draghi, bedrijft politiek; dat wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34304</th>\n",
       "      <td>1173861717358665728</td>\n",
       "      <td>2019-09-17 07:30:17+00:00</td>\n",
       "      <td>Â¿CÃ³mo serÃ¡n las #hipotecas con #Lagarde al fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34305</th>\n",
       "      <td>1173861522092765184</td>\n",
       "      <td>2019-09-17 07:29:30+00:00</td>\n",
       "      <td>Ma chronique hebdo taux @allnews_ch #Powell #f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34306</th>\n",
       "      <td>1173858586470080512</td>\n",
       "      <td>2019-09-17 07:17:50+00:00</td>\n",
       "      <td>Rencontre avec la presse europÃ©enne en #PlenPE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3123850 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                      date  \\\n",
       "0      1562541528740151296 2022-08-24 20:45:05+00:00   \n",
       "1      1562521759454138368 2022-08-24 19:26:32+00:00   \n",
       "2      1562515396330422275 2022-08-24 19:01:15+00:00   \n",
       "3      1562510373445545985 2022-08-24 18:41:17+00:00   \n",
       "4      1562499651952996352 2022-08-24 17:58:41+00:00   \n",
       "...                    ...                       ...   \n",
       "34302  1173870255543902214 2019-09-17 08:04:13+00:00   \n",
       "34303  1173862961817014273 2019-09-17 07:35:14+00:00   \n",
       "34304  1173861717358665728 2019-09-17 07:30:17+00:00   \n",
       "34305  1173861522092765184 2019-09-17 07:29:30+00:00   \n",
       "34306  1173858586470080512 2019-09-17 07:17:50+00:00   \n",
       "\n",
       "                                              rawContent  \n",
       "0      Economic Calendar for Tomorrow:\\n\\nðŸ‡©ðŸ‡ª1) German...  \n",
       "1      #EURUSD at 0.99 for the first time since 2003....  \n",
       "2      The European Central Bank (ECB) is planning to...  \n",
       "3      In the digital economy, cash is no longer a us...  \n",
       "4      Reading: What the U.S. Federal Reserve must do...  \n",
       "...                                                  ...  \n",
       "34302  Pulver endgÃ¼ltig verschossen, #EZB-Rat tief ge...  \n",
       "34303  #ECB, i.c. #Draghi, bedrijft politiek; dat wor...  \n",
       "34304  Â¿CÃ³mo serÃ¡n las #hipotecas con #Lagarde al fre...  \n",
       "34305  Ma chronique hebdo taux @allnews_ch #Powell #f...  \n",
       "34306  Rencontre avec la presse europÃ©enne en #PlenPE...  \n",
       "\n",
       "[3123850 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.concat(list_input_df)\n",
    "tweets_df[[\"id\", \"date\", \"rawContent\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e7a12d",
   "metadata": {},
   "source": [
    "Inspect the new data.frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa595f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3123850, 28)\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.shape)\n",
    "    #as many rows as tweets\n",
    "    #as many columns as features in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf09fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_type', 'url', 'date', 'rawContent', 'renderedContent', 'id', 'user',\n",
      "       'replyCount', 'retweetCount', 'likeCount', 'quoteCount',\n",
      "       'conversationId', 'lang', 'source', 'sourceUrl', 'sourceLabel', 'links',\n",
      "       'media', 'retweetedTweet', 'quotedTweet', 'inReplyToTweetId',\n",
      "       'inReplyToUser', 'mentionedUsers', 'coordinates', 'place', 'hashtags',\n",
      "       'cashtags', 'card'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7cda1f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_type                                  snscrape.modules.twitter.Tweet\n",
      "url                 https://twitter.com/harisonhbn9718/status/1562...\n",
      "date                                        2022-08-24 20:45:05+00:00\n",
      "rawContent          Economic Calendar for Tomorrow:\\n\\nðŸ‡©ðŸ‡ª1) German...\n",
      "renderedContent     Economic Calendar for Tomorrow:\\n\\nðŸ‡©ðŸ‡ª1) German...\n",
      "id                                                1562541528740151296\n",
      "user                {'_type': 'snscrape.modules.twitter.User', 'us...\n",
      "replyCount                                                          0\n",
      "retweetCount                                                        0\n",
      "likeCount                                                           0\n",
      "quoteCount                                                          0\n",
      "conversationId                                    1562541528740151296\n",
      "lang                                                               en\n",
      "source              <a href=\"https://mobile.twitter.com\" rel=\"nofo...\n",
      "sourceUrl                                  https://mobile.twitter.com\n",
      "sourceLabel                                           Twitter Web App\n",
      "links                                                            None\n",
      "media                                                            None\n",
      "retweetedTweet                                                    NaN\n",
      "quotedTweet                                                      None\n",
      "inReplyToTweetId                                                  NaN\n",
      "inReplyToUser                                                    None\n",
      "mentionedUsers                                                   None\n",
      "coordinates                                                      None\n",
      "place                                                            None\n",
      "hashtags                                                         None\n",
      "cashtags                                                         None\n",
      "card                                                             None\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#get all columns for the first tweet\n",
    "print(tweets_df.iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8bbda",
   "metadata": {},
   "source": [
    "Reset the indeces just in case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43d49db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1562541528740151296</td>\n",
       "      <td>2022-08-24 20:45:05+00:00</td>\n",
       "      <td>Economic Calendar for Tomorrow:\\n\\nðŸ‡©ðŸ‡ª1) German...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1562521759454138368</td>\n",
       "      <td>2022-08-24 19:26:32+00:00</td>\n",
       "      <td>#EURUSD at 0.99 for the first time since 2003....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1562515396330422275</td>\n",
       "      <td>2022-08-24 19:01:15+00:00</td>\n",
       "      <td>The European Central Bank (ECB) is planning to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1562510373445545985</td>\n",
       "      <td>2022-08-24 18:41:17+00:00</td>\n",
       "      <td>In the digital economy, cash is no longer a us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1562499651952996352</td>\n",
       "      <td>2022-08-24 17:58:41+00:00</td>\n",
       "      <td>Reading: What the U.S. Federal Reserve must do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123845</th>\n",
       "      <td>1173870255543902214</td>\n",
       "      <td>2019-09-17 08:04:13+00:00</td>\n",
       "      <td>Pulver endgÃ¼ltig verschossen, #EZB-Rat tief ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123846</th>\n",
       "      <td>1173862961817014273</td>\n",
       "      <td>2019-09-17 07:35:14+00:00</td>\n",
       "      <td>#ECB, i.c. #Draghi, bedrijft politiek; dat wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123847</th>\n",
       "      <td>1173861717358665728</td>\n",
       "      <td>2019-09-17 07:30:17+00:00</td>\n",
       "      <td>Â¿CÃ³mo serÃ¡n las #hipotecas con #Lagarde al fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123848</th>\n",
       "      <td>1173861522092765184</td>\n",
       "      <td>2019-09-17 07:29:30+00:00</td>\n",
       "      <td>Ma chronique hebdo taux @allnews_ch #Powell #f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123849</th>\n",
       "      <td>1173858586470080512</td>\n",
       "      <td>2019-09-17 07:17:50+00:00</td>\n",
       "      <td>Rencontre avec la presse europÃ©enne en #PlenPE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3123850 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id                      date  \\\n",
       "0        1562541528740151296 2022-08-24 20:45:05+00:00   \n",
       "1        1562521759454138368 2022-08-24 19:26:32+00:00   \n",
       "2        1562515396330422275 2022-08-24 19:01:15+00:00   \n",
       "3        1562510373445545985 2022-08-24 18:41:17+00:00   \n",
       "4        1562499651952996352 2022-08-24 17:58:41+00:00   \n",
       "...                      ...                       ...   \n",
       "3123845  1173870255543902214 2019-09-17 08:04:13+00:00   \n",
       "3123846  1173862961817014273 2019-09-17 07:35:14+00:00   \n",
       "3123847  1173861717358665728 2019-09-17 07:30:17+00:00   \n",
       "3123848  1173861522092765184 2019-09-17 07:29:30+00:00   \n",
       "3123849  1173858586470080512 2019-09-17 07:17:50+00:00   \n",
       "\n",
       "                                                rawContent  \n",
       "0        Economic Calendar for Tomorrow:\\n\\nðŸ‡©ðŸ‡ª1) German...  \n",
       "1        #EURUSD at 0.99 for the first time since 2003....  \n",
       "2        The European Central Bank (ECB) is planning to...  \n",
       "3        In the digital economy, cash is no longer a us...  \n",
       "4        Reading: What the U.S. Federal Reserve must do...  \n",
       "...                                                    ...  \n",
       "3123845  Pulver endgÃ¼ltig verschossen, #EZB-Rat tief ge...  \n",
       "3123846  #ECB, i.c. #Draghi, bedrijft politiek; dat wor...  \n",
       "3123847  Â¿CÃ³mo serÃ¡n las #hipotecas con #Lagarde al fre...  \n",
       "3123848  Ma chronique hebdo taux @allnews_ch #Powell #f...  \n",
       "3123849  Rencontre avec la presse europÃ©enne en #PlenPE...  \n",
       "\n",
       "[3123850 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = tweets_df.reset_index(drop=True)\n",
    "    #use drop drop parameter to avoid the old index being added as a column\n",
    "tweets_df[[\"id\", \"date\", \"rawContent\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6b8df5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check we have the expected number of rows\n",
    "tweets_df.shape[0] == sum([len(data_frame) for data_frame in list_input_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4887e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#release space\n",
    "import gc\n",
    "\n",
    "del(list_input_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663c593",
   "metadata": {},
   "source": [
    "## Process tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16cf625",
   "metadata": {},
   "source": [
    "First, check for duplicated tweets, i.e., the same tweet found in two different searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e0afe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"id\"].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ebbe49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look to one of the duplicated IDs\n",
    "example_duplicated_id = tweets_df[tweets_df[\"id\"].duplicated()].iloc[2,:].loc[\"id\"] #get the ID\n",
    "\n",
    "#get the URL for all tweets having the example ID and check if there are identical URLs\n",
    "tweets_df.loc[tweets_df[\"id\"] == example_duplicated_id, \"url\"].duplicated().any()\n",
    "    #tweets with the same ID have the same URL, so they are the same tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca583c",
   "metadata": {},
   "source": [
    "Remove duplicated tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf67a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2914653, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove tweets with a duplicated id\n",
    "tweets_df = tweets_df.drop_duplicates(subset=['id'])\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7a298",
   "metadata": {},
   "source": [
    "Now check language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6c6042d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am', 'ar', 'bg', 'bn', 'ca', 'ckb', 'cs', 'cy', 'da', 'de', 'el',\n",
       "       'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gu', 'hi', 'ht', 'hu',\n",
       "       'hy', 'in', 'is', 'it', 'iw', 'ja', 'ka', 'kn', 'ko', 'lt', 'lv',\n",
       "       'ml', 'mr', 'my', 'ne', 'nl', 'no', 'or', 'pa', 'pl', 'ps', 'pt',\n",
       "       'qam', 'qht', 'qme', 'qst', 'ro', 'ru', 'sd', 'si', 'sl', 'sr',\n",
       "       'sv', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'und', 'ur', 'vi', 'zh',\n",
       "       'zxx'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(tweets_df[\"lang\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64905741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405207"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see tweets not in english\n",
    "sum(tweets_df[\"lang\"] != \"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbabffd1",
   "metadata": {},
   "source": [
    "Select only tweets in English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d1fe64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2509446, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only tweets in english\n",
    "tweets_df_en = tweets_df[tweets_df[\"lang\"] == \"en\"]\n",
    "tweets_df_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae9dfbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#release space\n",
    "import gc\n",
    "\n",
    "del(tweets_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3eccb0",
   "metadata": {},
   "source": [
    "It seems that \"rawContent\" shows the raw tweet content, while \"renderedContent\" show the strings that would bet shown by the web app ([link](https://github.com/JustAnotherArchivist/snscrape/issues/479)). We are going to use the raw tweet because it seem it could have more information. They do not seem to be very different anyways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f3604c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Economic Calendar for Tomorrow:\\n\\nðŸ‡©ðŸ‡ª1) German...\n",
       "1    #EURUSD at 0.99 for the first time since 2003....\n",
       "2    The European Central Bank (ECB) is planning to...\n",
       "3    In the digital economy, cash is no longer a us...\n",
       "4    Reading: What the U.S. Federal Reserve must do...\n",
       "5    NEW - European Central Bankâ€™s Rehn: The invest...\n",
       "6    Crypto: European industry in danger! https://t...\n",
       "7    If there is one thing households in this count...\n",
       "8    @moonblocks_ @lucas_gool @FinanceChainge @Bloc...\n",
       "9    The European Central Bank creates a unified re...\n",
       "Name: rawContent, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_en.loc[:, \"rawContent\"].iloc[0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4ce0f8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Economic Calendar for Tomorrow:\\n\\nðŸ‡©ðŸ‡ª1) German...\n",
       "1    #EURUSD at 0.99 for the first time since 2003....\n",
       "2    The European Central Bank (ECB) is planning to...\n",
       "3    In the digital economy, cash is no longer a us...\n",
       "4    Reading: What the U.S. Federal Reserve must do...\n",
       "5    NEW - European Central Bankâ€™s Rehn: The invest...\n",
       "6    Crypto: European industry in danger! geeky.new...\n",
       "7    If there is one thing households in this count...\n",
       "8    @moonblocks_ @lucas_gool @FinanceChainge @Bloc...\n",
       "9    The European Central Bank creates a unified re...\n",
       "Name: renderedContent, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_en.loc[:, \"renderedContent\"].iloc[0:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a73e5",
   "metadata": {},
   "source": [
    "## Sentiment analysis of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909a71e",
   "metadata": {},
   "source": [
    "I will use VADER to perform the sentiment analysis. There are alternatives like TextBlob, but VADER meets well our requeriments: \n",
    "\n",
    "- It is sensitive to both polarity (positive/negative) and intensity (strength) of emotion.\n",
    "- Get a positive, negative neutral scores and a compound score.\n",
    "- Labelled data not required because it is pre-trained ([link](https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664), [link](https://towardsdatascience.com/sentiment-analysis-of-tweets-167d040f0583))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e3c3c",
   "metadata": {},
   "source": [
    "See functioning with a example tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68bfa516",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tweet = tweets_df_en.loc[1, \"rawContent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bcd2b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.252, 'neu': 0.71, 'pos': 0.038, 'compound': -0.8294}\n",
      "#EURUSD at 0.99 for the first time since 2003.\n",
      " The war, the energy crisis, the drought, but also the delayed reaction of the European Central Bank to moderate inflation weakened the EU currency. https://t.co/qkNjD8u8ND\n"
     ]
    }
   ],
   "source": [
    "#VADER can be used from vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#open instance\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#example\n",
    "print(analyzer.polarity_scores(example_tweet))\n",
    "print(example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821811c",
   "metadata": {},
   "source": [
    "The example tweet is cleary a negative tweet about Europe's situation and in particular the decision made by the ECB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadfeb68",
   "metadata": {},
   "source": [
    "Now compare the implementation of VADER in nlTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5b28906",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/dftortosa/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#or from nlTK\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "#instance\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77f486ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.252, 'neu': 0.71, 'pos': 0.038, 'compound': -0.8294}\n",
      "{'neg': 0.252, 'neu': 0.71, 'pos': 0.038, 'compound': -0.8294}\n"
     ]
    }
   ],
   "source": [
    "#we get similar results\n",
    "print(sid.polarity_scores(example_tweet))\n",
    "print(analyzer.polarity_scores(example_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f82468",
   "metadata": {},
   "source": [
    "Now, define a function to clean the tweet text and the to apply the sentiment analysis across the pandas DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5113922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()).replace(\"#\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abff86f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#EURUSD at 0.99 for the first time since 2003.\n",
      " The war, the energy crisis, the drought, but also the delayed reaction of the European Central Bank to moderate inflation weakened the EU currency. https://t.co/qkNjD8u8ND\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'EURUSD at 0.99 for the first time since 2003. The war the energy crisis the drought but also the delayed reaction of the European Central Bank to moderate inflation weakened the EU currency'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example_tweet)\n",
    "clean_tweet(example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf62362",
   "metadata": {},
   "source": [
    "Apply VADER to the cleaned tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d678eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.258, 'neu': 0.703, 'pos': 0.039, 'compound': -0.8294}\n"
     ]
    }
   ],
   "source": [
    "print(analyzer.polarity_scores(clean_tweet(example_tweet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45363c",
   "metadata": {},
   "source": [
    "We are going to use the compound sentiment. In this way, we consider both the negative and positive sentiment around the BCE and the economy of Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d09198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to be applied per row\n",
    "def sentiment_per_row(raw_tweet, sentiment_type=\"compound\"):\n",
    "        \n",
    "    #clean\n",
    "    tweet_cleaned = clean_tweet(raw_tweet)\n",
    "    \n",
    "    #get the negative sentiment\n",
    "    sentiment = analyzer.polarity_scores(tweet_cleaned)[sentiment_type]\n",
    "\n",
    "    #return\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54188b",
   "metadata": {},
   "source": [
    "Apply across rows in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64992870",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "with mp.Pool(10) as pool:\n",
    "    tweets_df_en[\"sentiment\"] = pool.map(sentiment_per_row, tweets_df_en[\"rawContent\"])\n",
    "        #for each row in tweets_df_en[\"rawContent\"], apply sentiment_per_row across 10 cores\n",
    "        #https://stackoverflow.com/questions/45545110/make-pandas-dataframe-apply-use-all-cores\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb06f3f",
   "metadata": {},
   "source": [
    "Subset to get only the date and the sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c4f7c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-24 20:45:05+00:00</td>\n",
       "      <td>-0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-24 19:26:32+00:00</td>\n",
       "      <td>-0.8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-24 19:01:15+00:00</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-24 18:41:17+00:00</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-24 17:58:41+00:00</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123824</th>\n",
       "      <td>2019-09-17 09:51:04+00:00</td>\n",
       "      <td>-0.9360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123825</th>\n",
       "      <td>2019-09-17 09:42:17+00:00</td>\n",
       "      <td>-0.2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123828</th>\n",
       "      <td>2019-09-17 09:29:04+00:00</td>\n",
       "      <td>-0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123829</th>\n",
       "      <td>2019-09-17 09:18:08+00:00</td>\n",
       "      <td>-0.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123842</th>\n",
       "      <td>2019-09-17 08:39:29+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2509446 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  sentiment\n",
       "0       2022-08-24 20:45:05+00:00    -0.7351\n",
       "1       2022-08-24 19:26:32+00:00    -0.8294\n",
       "2       2022-08-24 19:01:15+00:00     0.4404\n",
       "3       2022-08-24 18:41:17+00:00     0.4588\n",
       "4       2022-08-24 17:58:41+00:00    -0.2732\n",
       "...                           ...        ...\n",
       "3123824 2019-09-17 09:51:04+00:00    -0.9360\n",
       "3123825 2019-09-17 09:42:17+00:00    -0.2120\n",
       "3123828 2019-09-17 09:29:04+00:00    -0.1036\n",
       "3123829 2019-09-17 09:18:08+00:00    -0.0806\n",
       "3123842 2019-09-17 08:39:29+00:00     0.0000\n",
       "\n",
       "[2509446 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur = tweets_df_en[[\"date\", \"sentiment\"]]\n",
    "sentiment_results_df_eur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55176d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#release space\n",
    "import gc\n",
    "\n",
    "del(tweets_df_en)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8160df",
   "metadata": {},
   "source": [
    "In the date, leave only year, month and day because I only have one EUr pricing observation per day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d9821ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>-0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>-0.8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123824</th>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>-0.9360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123825</th>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>-0.2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123828</th>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>-0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123829</th>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>-0.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123842</th>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2509446 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  sentiment\n",
       "0       2022-08-24    -0.7351\n",
       "1       2022-08-24    -0.8294\n",
       "2       2022-08-24     0.4404\n",
       "3       2022-08-24     0.4588\n",
       "4       2022-08-24    -0.2732\n",
       "...            ...        ...\n",
       "3123824 2019-09-17    -0.9360\n",
       "3123825 2019-09-17    -0.2120\n",
       "3123828 2019-09-17    -0.1036\n",
       "3123829 2019-09-17    -0.0806\n",
       "3123842 2019-09-17     0.0000\n",
       "\n",
       "[2509446 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur[\"date\"] = pd.to_datetime(sentiment_results_df_eur[\"date\"].dt.strftime('%Y-%m-%d'))\n",
    "    #https://stackoverflow.com/questions/38067704/how-to-change-the-datetime-format-in-pandas\n",
    "    #https://stackoverflow.com/questions/20689288/converting-pandas-columns-to-datetime64-including-missing-values\n",
    "sentiment_results_df_eur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2dc8c",
   "metadata": {},
   "source": [
    "Check we have rows ordered in chronological order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8594a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur.equals(sentiment_results_df_eur.sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b544cd",
   "metadata": {},
   "source": [
    "Next, I am going to calculate several metrics for the sentiment of each day and save them in list of data frames. It is possible to calculate the mean, median, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c9895aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2007-01-11    0.458800\n",
       "2007-01-15    0.510600\n",
       "2007-01-30    0.000000\n",
       "2007-02-08    0.458800\n",
       "2007-03-07    0.458800\n",
       "                ...   \n",
       "2022-08-20   -0.018176\n",
       "2022-08-21   -0.050997\n",
       "2022-08-22   -0.031427\n",
       "2022-08-23   -0.003926\n",
       "2022-08-24   -0.024908\n",
       "Name: sentiment, Length: 5338, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a58947",
   "metadata": {},
   "source": [
    "I can also use lambda to define other calculations like the interquartile range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8a411d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2007-01-11    0.000000\n",
       "2007-01-15    0.000000\n",
       "2007-01-30    0.000000\n",
       "2007-02-08    0.000000\n",
       "2007-03-07    0.000000\n",
       "                ...   \n",
       "2022-08-20    0.840200\n",
       "2022-08-21    0.956225\n",
       "2022-08-22    0.790850\n",
       "2022-08-23    0.951000\n",
       "2022-08-24    0.850850\n",
       "Name: sentiment, Length: 5338, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].apply(lambda x: (np.percentile(x, 75) - np.percentile(x, 25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2d060a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2007-01-11         NaN\n",
       "2007-01-15         NaN\n",
       "2007-01-30         NaN\n",
       "2007-02-08    0.000000\n",
       "2007-03-07         NaN\n",
       "                ...   \n",
       "2022-08-20    0.529359\n",
       "2022-08-21    0.545527\n",
       "2022-08-22    0.499470\n",
       "2022-08-23    0.524858\n",
       "2022-08-24    0.523156\n",
       "Name: sentiment, Length: 5338, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6263813",
   "metadata": {},
   "source": [
    "std gives NA for cases with n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2aceeb4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "dtype: float64\n",
      "0    0.707107\n",
      "dtype: float64\n",
      "0   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame([1,1]).std()) #std = 0\n",
    "print(pd.DataFrame([1,2]).std()) #std = 0.7\n",
    "print(pd.DataFrame([1]).std()) #std = NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a5cb5",
   "metadata": {},
   "source": [
    "This is solved using ddof=0. ddof is Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd9f6198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "dtype: float64\n",
      "0    0.5\n",
      "dtype: float64\n",
      "0    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame([1,1]).std(ddof=0)) #std = 0\n",
    "print(pd.DataFrame([1,2]).std(ddof=0)) #std = 0.7\n",
    "print(pd.DataFrame([1]).std(ddof=0)) #std = NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549d360",
   "metadata": {},
   "source": [
    "I get the same results with np.std and .std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f91d58a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.std([1,1])) #std = 0\n",
    "print(np.std([1,2])) #std = 0.7\n",
    "print(np.std([1])) #std = NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a05daa",
   "metadata": {},
   "source": [
    "It is also possible calculate the range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7527831e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2007-01-11    0.0000\n",
       "2007-01-15    0.0000\n",
       "2007-01-30    0.0000\n",
       "2007-02-08    0.0000\n",
       "2007-03-07    0.0000\n",
       "               ...  \n",
       "2022-08-20    1.9142\n",
       "2022-08-21    1.9470\n",
       "2022-08-22    1.9297\n",
       "2022-08-23    1.9362\n",
       "2022-08-24    1.8991\n",
       "Name: sentiment, Length: 5338, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].apply(lambda x: np.max(x) - np.min(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fce240",
   "metadata": {},
   "source": [
    "Variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10cdbc6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2007-01-11         NaN\n",
       "2007-01-15         NaN\n",
       "2007-01-30         NaN\n",
       "2007-02-08    0.000000\n",
       "2007-03-07         NaN\n",
       "                ...   \n",
       "2022-08-20    0.280221\n",
       "2022-08-21    0.297600\n",
       "2022-08-22    0.249470\n",
       "2022-08-23    0.275476\n",
       "2022-08-24    0.273692\n",
       "Name: sentiment, Length: 5338, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf3382d",
   "metadata": {},
   "source": [
    "I am going to use evaluate inside the function in order to perform different operations. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35d76d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].mean().to_frame()'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation=\"mean\"\n",
    "string_evaluate = 'sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].' + operation + '().to_frame()'\n",
    "string_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68fa6a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-11</th>\n",
       "      <td>0.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-15</th>\n",
       "      <td>0.510600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-30</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-08</th>\n",
       "      <td>0.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-07</th>\n",
       "      <td>0.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-20</th>\n",
       "      <td>-0.018176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-21</th>\n",
       "      <td>-0.050997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-22</th>\n",
       "      <td>-0.031427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-23</th>\n",
       "      <td>-0.003926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24</th>\n",
       "      <td>-0.024908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5338 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment\n",
       "date                 \n",
       "2007-01-11   0.458800\n",
       "2007-01-15   0.510600\n",
       "2007-01-30   0.000000\n",
       "2007-02-08   0.458800\n",
       "2007-03-07   0.458800\n",
       "...               ...\n",
       "2022-08-20  -0.018176\n",
       "2022-08-21  -0.050997\n",
       "2022-08-22  -0.031427\n",
       "2022-08-23  -0.003926\n",
       "2022-08-24  -0.024908\n",
       "\n",
       "[5338 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(string_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a165e15f",
   "metadata": {},
   "source": [
    "I am interested in having a row per day irrespectively of having or not sentiment data. In this way, I can exactly calculate the sentiment of 1, 10... days ago:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b6eee",
   "metadata": {},
   "source": [
    "It is possible to use min and max to select the earliest and latest dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91ce44fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-01-11T00:00:00.000000000\n",
      "2022-08-24T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "print(np.min(np.unique(sentiment_results_df_eur[\"date\"])))\n",
    "print(np.max(np.unique(sentiment_results_df_eur[\"date\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9831a05d",
   "metadata": {},
   "source": [
    "First, calculate the time range from the earliest to latest date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36a107bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2007-01-11', '2007-01-12', '2007-01-13', '2007-01-14',\n",
       "               '2007-01-15', '2007-01-16', '2007-01-17', '2007-01-18',\n",
       "               '2007-01-19', '2007-01-20',\n",
       "               ...\n",
       "               '2022-08-15', '2022-08-16', '2022-08-17', '2022-08-18',\n",
       "               '2022-08-19', '2022-08-20', '2022-08-21', '2022-08-22',\n",
       "               '2022-08-23', '2022-08-24'],\n",
       "              dtype='datetime64[ns]', length=5705, freq='D')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.date_range(np.min(np.unique(sentiment_results_df_eur[\"date\"])), \n",
    "                    np.max(np.unique(sentiment_results_df_eur[\"date\"])))\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e6d30",
   "metadata": {},
   "source": [
    "As an example, calculate the mean sentiment in tweets per day and then re-index considering all days between the earliest and latest date. Those dates without tweets will have NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d548b35c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007-01-11    0.458800\n",
       "2007-01-12         NaN\n",
       "2007-01-13         NaN\n",
       "2007-01-14         NaN\n",
       "2007-01-15    0.510600\n",
       "                ...   \n",
       "2022-08-20   -0.018176\n",
       "2022-08-21   -0.050997\n",
       "2022-08-22   -0.031427\n",
       "2022-08-23   -0.003926\n",
       "2022-08-24   -0.024908\n",
       "Freq: D, Name: sentiment, Length: 5705, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].mean().reindex(idx, fill_value=np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c060fd8",
   "metadata": {},
   "source": [
    "You can see how there is a gap without tweets between 11 and 15 of January and, accordingly, the days in between have NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a22455",
   "metadata": {},
   "source": [
    "It is also possible to shift the rows after making an operation per day, i.e., move the value of day 1 to day 2, value of day 2 to day 3, and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5377d70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007-01-11    0.458800\n",
       "2007-01-12         NaN\n",
       "2007-01-13         NaN\n",
       "2007-01-14         NaN\n",
       "2007-01-15    0.510600\n",
       "                ...   \n",
       "2022-08-20   -0.018176\n",
       "2022-08-21   -0.050997\n",
       "2022-08-22   -0.031427\n",
       "2022-08-23   -0.003926\n",
       "2022-08-24   -0.024908\n",
       "Freq: D, Name: sentiment, Length: 5705, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first calculate the average sentiment per day\n",
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].mean().reindex(idx, fill_value=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7faf8907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007-01-11         NaN\n",
       "2007-01-12    0.458800\n",
       "2007-01-13         NaN\n",
       "2007-01-14         NaN\n",
       "2007-01-15         NaN\n",
       "                ...   \n",
       "2022-08-20   -0.002530\n",
       "2022-08-21   -0.018176\n",
       "2022-08-22   -0.050997\n",
       "2022-08-23   -0.031427\n",
       "2022-08-24   -0.003926\n",
       "Freq: D, Name: sentiment, Length: 5705, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now shift 2 days, so 2022-08-24 has now the average of the previous day (2022-08-23)\n",
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].mean().reindex(idx, fill_value=np.NaN).shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69a417",
   "metadata": {},
   "source": [
    "Shift zero would be equal to the original variable, no change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ef15266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].mean().reindex(idx, fill_value=np.NaN).shift(0).equals(sentiment_results_df_eur.groupby(\"date\")[\"sentiment\"].mean().reindex(idx, fill_value=np.NaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60ecd6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results_df_eur[\"sentiment\"].shift(0).equals(sentiment_results_df_eur[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00f9f4",
   "metadata": {},
   "source": [
    "Now, I am going to calculate different summary statistics of the sentiment of the previous days using two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85afe813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def groupby_calcs(operation, metric_name, args=\"\", n_previous_days=1, currency=\"\"):\n",
    "        \n",
    "    #get the string with the operation name\n",
    "    string_evaluate = 'sentiment_results_df_' + currency + '.groupby(\"date\")[\"sentiment\"].' + operation + '(' + args + ').to_frame()'\n",
    "        #do operations for the sentiment of each day and then convert to df\n",
    "\n",
    "    #evaluate to get the DF with the calculations per day\n",
    "    data_frame = eval(string_evaluate)\n",
    "    \n",
    "    #extract the range of days for which we have data\n",
    "    time_range = pd.date_range(np.min(np.unique(data_frame.index)), \n",
    "                        np.max(np.unique(data_frame.index)))\n",
    "    \n",
    "    #fill with NaN those dates with data\n",
    "    data_frame = data_frame.reindex(time_range, fill_value=np.NaN)\n",
    "        #https://stackoverflow.com/questions/15610805/accessing-row-from-previous-day-in-pandas-dataframe-with-apply\n",
    "    \n",
    "    #get sentiment of the previous days\n",
    "    data_frame['sentiment'] = data_frame['sentiment'].shift(n_previous_days)\n",
    "        #https://stackoverflow.com/questions/19324453/add-missing-dates-to-pandas-dataframe\n",
    "        \n",
    "    #reset the index\n",
    "    data_frame = data_frame.reset_index(level=0)\n",
    "        #set the index (date) as column \n",
    "  \n",
    "    #change the column name for sentiment\n",
    "    data_frame = data_frame.rename(columns={'index': 'date', 'sentiment': metric_name + '_sent_' + currency + '_previous_' + str(n_previous_days) + '_days'})\n",
    "\n",
    "    #append the df to the list\n",
    "    return data_frame\n",
    "    \n",
    "def groupby_calcs_across_dates(list_metrics, previous_date, currency=\"\"):\n",
    "        \n",
    "    #open list to save each calculation\n",
    "    list_data_frames = []\n",
    "    \n",
    "    #apply each operation\n",
    "    for metric in list_metrics:\n",
    "        \n",
    "        #for std\n",
    "        if metric == \"std\":\n",
    "            #use ddof=0 to get zero for cases with 1 tweet per day (see above)\n",
    "            result_calc = groupby_calcs(operation=metric, \n",
    "                          metric_name=metric, \n",
    "                          args='ddof=0', \n",
    "                          n_previous_days=previous_date, \n",
    "                          currency=currency)\n",
    "        elif \"quantile\" in metric: #if quantile\n",
    "            #get the operation name and the quantile number\n",
    "            operation_name = metric.split(\"_\")[0]\n",
    "            quantile_number = metric.split(\"_\")[1]\n",
    "            result_calc = groupby_calcs(operation=operation_name, \n",
    "                          metric_name=metric, \n",
    "                          args=quantile_number, \n",
    "                          n_previous_days=previous_date, \n",
    "                          currency=currency) \n",
    "        elif \"range\" in metric:\n",
    "            result_calc = groupby_calcs(operation=\"apply\", \n",
    "                          metric_name=metric, \n",
    "                          args=\"lambda x: np.max(x) - np.min(x)\",\n",
    "                          n_previous_days=previous_date, \n",
    "                          currency=currency)\n",
    "        elif \"iqr\" in metric:\n",
    "            result_calc = groupby_calcs(operation=\"apply\", \n",
    "                          metric_name=metric, \n",
    "                          args=\"lambda x: (np.percentile(x, 75) - np.percentile(x, 25))\",\n",
    "                          n_previous_days=previous_date, \n",
    "                          currency=currency)   \n",
    "        else: \n",
    "            result_calc = groupby_calcs(operation=metric, \n",
    "                          metric_name=metric, \n",
    "                          n_previous_days=previous_date, \n",
    "                          currency=currency)\n",
    "        \n",
    "        #save in the list  \n",
    "        list_data_frames.append(result_calc)\n",
    "    return list_data_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af8946",
   "metadata": {},
   "source": [
    "Define a list with the metrics to be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee0fd8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a list of operations to do\n",
    "list_metrics = [\"quantile_0.05\",\n",
    "                \"quantile_0.1\",\n",
    "                \"quantile_0.2\",\n",
    "                \"quantile_0.3\",\n",
    "                \"quantile_0.4\",\n",
    "                \"quantile_0.5\",\n",
    "                \"quantile_0.6\",\n",
    "                \"quantile_0.7\",\n",
    "                \"quantile_0.8\",\n",
    "                \"quantile_0.9\",\n",
    "                \"quantile_0.95\",\n",
    "                \"mean\",\n",
    "                \"min\",\n",
    "                \"max\",\n",
    "                \"sum\",\n",
    "                \"count\", \n",
    "                    #this can be useful to control for averages with low number of tweets\n",
    "                    #but also to consider how much people is talking about Europe's economy \n",
    "                \"range\", \n",
    "                \"var\", \n",
    "                \"std\", \n",
    "                \"iqr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "050cf24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           date  mean_sent_eur_previous_2_days\n",
       " 0    2007-01-11                            NaN\n",
       " 1    2007-01-12                            NaN\n",
       " 2    2007-01-13                       0.458800\n",
       " 3    2007-01-14                            NaN\n",
       " 4    2007-01-15                            NaN\n",
       " ...         ...                            ...\n",
       " 5700 2022-08-20                       0.013711\n",
       " 5701 2022-08-21                      -0.002530\n",
       " 5702 2022-08-22                      -0.018176\n",
       " 5703 2022-08-23                      -0.050997\n",
       " 5704 2022-08-24                      -0.031427\n",
       " \n",
       " [5705 rows x 2 columns],\n",
       "            date  count_sent_eur_previous_2_days\n",
       " 0    2007-01-11                             NaN\n",
       " 1    2007-01-12                             NaN\n",
       " 2    2007-01-13                             1.0\n",
       " 3    2007-01-14                             NaN\n",
       " 4    2007-01-15                             NaN\n",
       " ...         ...                             ...\n",
       " 5700 2022-08-20                           592.0\n",
       " 5701 2022-08-21                           504.0\n",
       " 5702 2022-08-22                           406.0\n",
       " 5703 2022-08-23                           450.0\n",
       " 5704 2022-08-24                           647.0\n",
       " \n",
       " [5705 rows x 2 columns]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_calcs_across_dates(list_metrics=[\"mean\", \"count\"], previous_date=2, currency=\"eur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30850ae6",
   "metadata": {},
   "source": [
    "I am going to calculate the summary statistics for the sentiment several days before the current day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6753ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dates = np.arange(1, 16, 1)\n",
    "\n",
    "#open a pool with 10 processes\n",
    "pool_dates = mp.Pool(processes=10)\n",
    "\n",
    "#apply the function for each previous day in parallel across 10 cores\n",
    "list_data_frames = [pool_dates.apply_async(groupby_calcs_across_dates, args=(list_metrics, previous_date, \"eur\")).get() for previous_date in list_dates]\n",
    "    #https://stackoverflow.com/questions/42843203/how-to-get-the-result-of-multiprocessing-pool-apply-async\n",
    "\n",
    "#close the pool\n",
    "pool_dates.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805370fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#release space\n",
    "import gc\n",
    "\n",
    "del(sentiment_results_df_eur)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18060ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_data_frames[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e78ad",
   "metadata": {},
   "source": [
    "Flat the list to get just a list of data frame and not a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae324d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in list_data_frames for item in sublist]\n",
    "flat_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35108075",
   "metadata": {},
   "source": [
    "Check we have the correct number of data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15138e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flat_list) == len(list_metrics) * len(list_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a9b09e",
   "metadata": {},
   "source": [
    "Merge all data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7fc345",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "#merge them using reduce\n",
    "df_merged = reduce(lambda left, right: pd.merge(left, right, on=['date'], how='inner'), [element for element in flat_list])\n",
    "    #https://stackoverflow.com/questions/44327999/python-pandas-merge-multiple-dataframes\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087cecc",
   "metadata": {},
   "source": [
    "## See NaN and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ec524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#see NaN\n",
    "print(df_merged.isnull().sum())\n",
    "    #We have NaNs for days that do not have prior twitter data in the selected previous day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18696f4e",
   "metadata": {},
   "source": [
    "We cannot just set as zero those NaN cases because I am using a compound sentiment (-1 to 1), so 0 is nuetral and lower (negative) values means negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"quantile_0.05_sent_eur_previous_1_days\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ee5e5",
   "metadata": {},
   "source": [
    "Remove these NA cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94910e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged = df_merged.dropna()\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c36c0a",
   "metadata": {},
   "source": [
    "Plot all the metrics only for the previous day (1 day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d55472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for each metric\n",
    "for metric in list_metrics:\n",
    "    \n",
    "    #plot scatter against date and eur pricing\n",
    "    plt.scatter(df_merged[\"date\"], df_merged[metric + \"_sent_eur_previous_1_days\"], s=0.5)\n",
    "\n",
    "    #set ylabel\n",
    "    plt.ylabel(metric + \" sentiment\")\n",
    "\n",
    "    #close\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b6944f",
   "metadata": {},
   "source": [
    "Save the final data frame with EUR sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47baacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"results/twitter_sentiment_data_eur.csv.gz\", compression=\"gzip\", index=False)\n",
    "#df_merged = pd.read_csv(\"results/twitter_sentiment_data.csv.gz\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
